import json
import asyncio
from audioop import error

import requests
from bs4 import BeautifulSoup
import re
import boto3

# Todo: Add try catch to handle no value
def getAttributes(url):
    products = json.load(open("tukku_products.json"))
    for index, product in enumerate(products):
        if index<1:
            url = product['url']
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")
            get_common_attributes(product, soup)
            get_specific_attibute(product, soup)

    with open("tukku_products_all.json", "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=2)


async def get_common_attributes(product, soup):

    await asyncio.gather(
        get_image_url(product, soup),
        get_brand(product, soup),
        get_delivery_time(product, soup),
        get_price(product, soup),
        get_discount(product, soup),
        get_description(product, soup),
        get_stock(product, soup),
        get_category(product, soup),
        get_review_and_rating(product, soup)
    )


async def get_review_and_rating(product, soup):
    try:
        reviews = soup.find("div", class_="comments_note").find("span", class_="nb-comments").get_text(strip=True)
        star_rating = len(soup.find("div", class_="star_content").find_all("div", class_="star"))
    except:
        reviews = "No reviews"
        star_rating = 0
    product["star_rating"] = star_rating
    product["reviews"] = reviews


def get_specific_attibute(product, soup):
    from openai import OpenAI
    with OpenAI(
            api_key="sk-6Kdct2IBYgkgvEie96E2C33dF5D0484dB80d9a9674DfFf41",
            base_url="https://ai-yyds.com/v1"
    ) as client:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "Based on the description I give, please return key-value string pairs supporting search engine searching with related products. No name and description required. Make sure the output contains no escape characters or additional formatting. Do not include backslashes or any unnecessary characters. List at most 10 specifications that buyers care about when purchasing this kind of product. Keep it short and concise. Only return the dictionary itself, and the language should be English.This is the description:" + product['description'],
                }
            ],
            temperature=0.0,
        )
        result = re.sub(r"\\", "",  response.choices[0].message.content)
        product['attributes'] = result

def get_specific_attribute_ollama():
    url = "http://195.148.30.36:11434/api/generate"
    data = {
        "model": "llama3.2",  # Specify the model you deployed
        "prompt": "Explain the concept of machine learning in simple terms."
    }
    response = requests.post(url, json=data)
    if response.status_code == 200:
        # Parse the response JSON
        # result = response.json()
        print("Response:", response)  # Output the text generated by the model
    else:
        print(f"Error: {response.status_code}, {response.text}")

async def get_description(product, soup):
    descriptions = soup.find("div", class_="product-description").find_all("p")
    description = "\n".join(p.get_text(strip=True) for p in descriptions)
    if description == "":
        description = soup.find("div", class_="product-description").find_all("div")
        description = "\n".join(p.get_text(strip=True) for p in description)
    if description == "":
        description = product["name"]
    product["description"] = description

async def get_image_url(product, soup):
    image_url = ""
    try:
        img_tag = soup.find("img", class_="js-qv-product-cover")
        image_url = img_tag["src"] if img_tag else ""

    except error as e:
        image_url=""
        print(f"exception{e}")
    product["image_url"]=image_url

async def get_category(product, soup):
    breadcrumn = soup.find("nav", class_="breadcrumb")
    if breadcrumn:
        categories = [span.get_text(strip=True) for span in breadcrumn.find_all("span", itemprop="name")]
    else:
        categories = []
    product["categories"] = categories
async def get_name(product, soap):
    product["name"] = (
        soap.find("h3", class_="h3 product-title").find("a").text.strip()
    )

async def get_id(product, soap):
    product["id"] = (
        soap.find("p", class_="pl_reference").find("strong").text.strip()
    )

async def get_url(product, soap):
    product["url"] = soap.find("h3", class_="h3 product-title").find("a")[
        "href"
    ]

async def get_price(product, soup):
    try:
        product_price = (
            soup.find("div", class_="product-price-and-shipping")
            .find("span", "price")
            .text.strip()
        )
    except:
        product_price = ""
    product["price"] = product_price

async def get_brand(product, soup):
    try:
        with open("currentProduct.html", "w", encoding="utf-8") as file:
            file.write(soup.prettify())
        brand_div = soup.find("div", id="product_manufacturer")
        if brand_div:
            brand_label = brand_div.find("label", class_="label")
            brand_text = brand_label.get_text(strip=True) if brand_label else ""
        else:
            brand_text = ""
    except Exception as e:
        print(e)
    product["brand"] = brand_text

async def get_delivery_time(product, soap):
    try:
        delivery = soap.find("span", id="product-availability").text.strip()
        delivery_time = re.search(r'\b\d+(\.\d+)?\b', delivery)
        delivery_time = delivery_time.group(0) if delivery_time else None
        product["delivery"] =delivery_time
    except Exception as e:
        print(e)

async def get_discount(product, soap):
    discount = soap.find("span", class_="discount discount-amount")
    discount = discount.text.strip() if discount else None
    match = re.search(r'\d+,\d+', discount) if discount else None
    product["discount"] = match.group(0) if match else None

async def get_stock(product, soap):
    stock = soap.find("span", {'data-stock': True})
    stock_value = stock['data-stock'] if stock else None
    product["stock"] = stock_value

# the common attributes are id, name, description, price, category, brand, stock, discount , delivery_time

# def getCommonAttributes(url):
#
# # other attributes
# def getSpecificAttributes(url):

 
# AWS Translate function
def translate_text(text, source_language="fi", target_language="en"):
    translator = boto3.client(
        service_name="translate", region_name="eu-west-1", use_ssl=True
    )
    response = translator.translate_text(
        Text=text,
        SourceLanguageCode=source_language,
        TargetLanguageCode=target_language
    )
    return response['TranslatedText']
 
async def translate_product_data(products):
    translated_products = []
    for product in products:
        translated_product = {}
        for key, value in product.items():
            if isinstance(value, str):  # Only translate text fields
                translated_product[key] = translate_text(value)
            else:
                translated_product[key] = value
        translated_products.append(translated_product)
    return translated_products
 
# Integrate the translation function with get_individual()
async def get_and_translate_individual():
 
    # Read the processed product data from JSON
    with open("tukku_products_detail_all.json", "r", encoding="utf-8") as f:
        products = json.load(f)
 
    # Translate the product data
    translated_products = await translate_product_data(products)
 
    # Save the translated data to a new JSON file
    with open("tukku_products_detail_translated.json", "w", encoding="utf-8") as f:
        json.dump(translated_products, f, ensure_ascii=False, indent=2)
  

if __name__ == "__main__":
    # getAttributes('')
    get_specific_attribute_ollama()